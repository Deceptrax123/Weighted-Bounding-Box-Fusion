{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part of code taken from https://learnopencv.com/weighted-boxes-fusion/\n",
    "\n",
    "import torch \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import os\n",
    "from ensemble_boxes import *\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/smudge/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-9-28 Python-3.11.4 torch-2.1.0 MPS\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "Using cache found in /Users/smudge/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-9-28 Python-3.11.4 torch-2.1.0 MPS\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model_1=torch.hub.load(\"ultralytics/yolov5\",'custom',path='best_yolov5_weights.pt',device=torch.device('mps'))\n",
    "model_2=torch.hub.load(\"ultralytics/yolov5\",'custom',path='last.pt',device=torch.device('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the env variables\n",
    "load_dotenv('./.env')\n",
    "PATH_TO_TEST=os.getenv(\"PATH_TO_TEST\")\n",
    "PATH_TO_INPAINT=os.getenv(\"PATH_TO_INPAINT\")\n",
    "PATH_TO_AUTO=os.getenv(\"PATH_TO_AUTO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the image ids\n",
    "test_ids=os.listdir(PATH_TO_TEST)\n",
    "inpaint_ids=os.listdir(PATH_TO_INPAINT)\n",
    "auto_ids=os.listdir(PATH_TO_AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predictions\n",
    "\n",
    "def get_predictions(img_names,path,aug,model):\n",
    "\n",
    "    model.conf=0.25\n",
    "\n",
    "    pred_scores=dict()\n",
    "    pred_boxes=dict()\n",
    "    pred_classes=dict()\n",
    "\n",
    "    for img in img_names:\n",
    "        if '_' not in img:\n",
    "            img_path=path+img\n",
    "\n",
    "            prediction=model(img_path,size=1024,augment=aug)\n",
    "\n",
    "            pred_scores[img]=prediction.xyxy[0][:,4].to(device=torch.device('cpu')).detach().numpy()\n",
    "            pred_boxes[img]=prediction.xyxy[0][:,0:4].to(device=torch.device('cpu')).detach().numpy()\n",
    "            pred_classes[img]=prediction.xyxy[0][:,5].to(device=torch.device('cpu')).detach().numpy()\n",
    "    \n",
    "    return pred_scores,pred_boxes,pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions for different test sets\n",
    "\n",
    "pred_confs=[]\n",
    "pred_boxes=[]\n",
    "pred_classes=[]\n",
    "\n",
    "test_paths=[PATH_TO_TEST,PATH_TO_INPAINT,PATH_TO_AUTO]\n",
    "test_imgids=[test_ids,inpaint_ids,auto_ids]\n",
    "models=[model_1,model_2]\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    considered_model=models[i]\n",
    "    for j in range(3):\n",
    "        confs_scores,box_preds,cls_pred=get_predictions(test_imgids[j],test_paths[j],aug=False,model=considered_model)\n",
    "\n",
    "        pred_confs.append(confs_scores)\n",
    "        pred_boxes.append(box_preds)\n",
    "        pred_classes.append(cls_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for weighted box fusion\n",
    "def perform_wbf(pred_confs_models,pred_boxes_models,pred_classes_models):\n",
    "    wbf_boxes_dict=dict()\n",
    "    wbf_scores_dict=dict()\n",
    "\n",
    "    for image_id in test_ids:\n",
    "        if '_' not in image_id:\n",
    "            res_array=np.array([1024,1024,1024,1024]) #1024X1024 images\n",
    "\n",
    "            all_model_boxes=[]\n",
    "            all_model_scores=[]\n",
    "            all_model_classes=[]\n",
    "\n",
    "            for boxes,scores,classes in zip(pred_boxes_models,pred_confs_models,pred_classes_models):\n",
    "                pred_boxes_norm=(boxes[image_id]/res_array).clip(min=0.,max=1.)\n",
    "                scores_model=scores[image_id]\n",
    "                classes_model=classes[image_id]\n",
    "\n",
    "                all_model_boxes.append(pred_boxes_norm)\n",
    "                all_model_scores.append(scores_model)\n",
    "                all_model_classes.append(classes_model)\n",
    "            \n",
    "            boxes,scores,labels=weighted_boxes_fusion(all_model_boxes,all_model_scores,all_model_classes,weights=None,iou_thr=0.5,skip_box_thr=0.25)\n",
    "\n",
    "            final_score_ids=np.where(scores>0.26)[0]\n",
    "            final_boxes=boxes[final_score_ids]\n",
    "            final_scores=scores[final_score_ids]\n",
    "\n",
    "            final_boxes=(final_boxes*res_array).clip(min=[0,0,0,0],max=[1023,1023,1023,1023])\n",
    "\n",
    "            final_boxes=final_boxes.astype(\"int\")\n",
    "\n",
    "            final_boxes[:,2:]=final_boxes[:,2:]-final_boxes[:,:2]\n",
    "            wbf_boxes_dict[image_id]=final_boxes.tolist()\n",
    "            wbf_scores_dict[image_id]=np.expand_dims(np.round(final_scores,5),axis=-1).tolist()\n",
    "    \n",
    "    return wbf_boxes_dict,wbf_scores_dict\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_dict_wbf,scores_dict_wbf=perform_wbf(pred_confs,pred_boxes,pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save outputs to csv file\n",
    "\n",
    "boxes=list()\n",
    "ids=list()\n",
    "scores=list()\n",
    "for i in boxes_dict_wbf.keys():\n",
    "    boxes.append(boxes_dict_wbf[i])\n",
    "    ids.append(i)\n",
    "    scores.append(scores_dict_wbf[i])\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'image_id':ids,\n",
    "    'boxes':boxes,\n",
    "    'scores':scores\n",
    "})\n",
    "\n",
    "df.to_csv(\"./Results/ensemble_test_auto_inpaint_conf_0.25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
